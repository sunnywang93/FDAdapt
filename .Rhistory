list(
t = curve$t,
x = curve$x + mu_t$mu[idx])
})
holder_estim <- estimate_holder_quantities(pfbm_mu, grid_param)
# cov_gkp <- covariance_ll(pfbm_mu, grid_bandwidth, grid_smooth, k0,
#                          holder_estim)
# elements_gkp <- funeigen:::normalise_eigen(cov_gkp$cov, nvalues = nvalues)
# evalues_gkp <- elements_gkp$values
# efunctions_gkp <- elements_gkp$vectors
# evalues_pw <- evalues_adaptive(pfbm_mu, grid_bandwidth, grid_smooth,
#                                k0, nvalues, holder_estim)
curves =  pfbm_mu
params = holder_estim
# smooth_curves <- smooth_curves_evalues(curves, grid_bandwidth,
#                                        grid_smooth, k0, nvalues, params)
# bw_vector <- estimate_bandwidth_evalues(curves, grid_bandwidth,
#                                         grid_smooth, k0,
#                                         nvalues, params)
# cov_gkp2 <- covariance_norm(curves, grid_bandwidth, grid_smooth,
#                            k0, params)
# grid_tibble = holder_estim
m <- purrr::map_dbl(curves, ~length(.x$t)) |> mean()
interp_grid <- c(0, params$t, 1)
var_interp <- as.matrix(params[, c("H", "L", "sigma", "mu0")])
interp_mat <- apply(var_interp, MARGIN = 2,
function(x) pracma::interp1(x = interp_grid,
y = c(x[1], x, x[nrow(var_interp)]),
xi = grid_smooth))
grid_tibble <- tibble::as_tibble(cbind(t = grid_smooth, interp_mat))
bandwidth_list <- estimate_bandwidth_covariance_norm(curves,
grid_bandwidth,
grid_smooth,
k0,
grid_tibble)
}
test[1]
tictoc::toc()
stopCluster(cl)
estimate_bandwidth_covariance_norm
params
source("/Users/swang/Dropbox/FPCA/simuls/nice_dgp/dgp.R")
#source("/Users/swang/Dropbox/Mac/Downloads/juin15/codes_val/dgp_old.R")
# source("/Users/swang/Dropbox/funeigen/R/H_and_L_functions.R")
# source("/Users/swang/Dropbox/funeigen/R/mean_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/cov_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/utils.R")
# source("/Users/swang/Dropbox/funeigen/R/eigenvalues.R")
library(funeigen)
library(foreach)
library(fs)
library(doParallel)
library(functional)
library(purrr)
#parameters
N <- 200
M <- 25
#H <- c(0.5, 0.8)
sigma <- 0.5
L <- 1
mu0 <- 1
grid_size_true <- 101
grid_true <- seq(0, 1, length.out = grid_size_true)
grid_mu <- seq(0, 1, length.out = 1001)
grid_smooth <- seq(0, 1, length.out = 101)
grid_bandwidth <- lseq(0.001, 0.1, length.out = 51)
grid_param = seq(0.1, 0.9, length.out = 20)
k0 <- 1
n_simu <- 45
tau <- 2.5 #variance of random starting points
nvalues <- 10
nfunctions <- 10
points_dist <- Curry(runif, min = 0, max = 1) #distribution of Ti
#learn true quantities from dataset powerconsumption ===========================
library(simulater)
library(fda)
df <- powerconsumption
df_list <- list()
for (idx in 1:nrow(df)) {
df_list[[idx]] <- list(
't' = seq(0, 1, length.out = 1440),
'x' = unname(unlist(as.vector(df[idx,])))
)
}
n_basis <- 9  #other tested setups 7
t0_list <- seq(.1, .9, l = 40)
grid <- seq(.1, .9, l = 101)
#df_smooth <- presmoothing(df_list, t0_list = t0_list, estimate_sigma(df_list))
df_smooth <- funestim::presmoothing(df_list, t0_list)
H0 <- funestim::estimate_H0(df_smooth)
L0 <- funestim::estimate_L0(df_smooth, H0, M)
true_tibble = tibble::tibble(t = t0_list, H = H0, L = L0, sigma = sigma,
mu0 = mu0)
basis <- create.fourier.basis(rangeval = c(min(t0_list), max(t0_list)),
nbasis = n_basis)
H0_smooth <- smooth.basis(argvals = t0_list, y = H0, fdParobj = basis)
L0_smooth <- smooth.basis(argvals = t0_list, y = L0, fdParobj = basis)
H0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(H0_smooth))[, 1]
L0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(L0_smooth))[, 1]
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
constant_fun <- approxfun(
x = grid, y = L0_eval,
yleft = L0_eval[1], yright = L0_eval[length(L0_eval)]
)
grid_large <- seq(0, 1, l = 10001)
A_hat_prime <- constant_fun(grid_large)**(1 / hurst_fun(grid_large))
A_hat <- pracma::cumtrapz(x = grid_large, y = A_hat_prime)
A_fun <- approxfun(
x = grid_large, y = A_hat,
yleft = A_hat[1], yright = A_hat[length(A_hat)]
)
s <- exp(-3)  # Regularity for the estimation of the mean
##other tested setups 3
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
#true mean
mu_model <- learn_mean(df, k = 50)
mu <- predict_mean(grid_mu, mu_model, lambda = s, k = 50) - 240
mu_t <- tibble::tibble(t = grid_mu, mu)
#tested discretisation error on grid of 1001 points - very small
grid_cov <- seq(0, 1, length.out = 101)
pp_disto <- A_fun(grid_cov)
cov_true <- tau**2 + covariance_mfbm(grid_cov, hurst_fun, pp_disto)
#obtain the "numerically true" eigenvalues from the true covariance
evalues_true <- eigen(cov_true, symmetric = TRUE,
only.values = TRUE)$values[1:nvalues] / length(grid_cov)
efunctions_true <- eigen(cov_true, symmetric = TRUE)$vectors[, 1:nvalues] *
sqrt(length(grid_cov))
rm(sigma)
sigma = 0.5
points_list <- generates_points(N = N, m = M)
pfbm <- generate_curves(points_list, hurst_fun,
distortion_model = A_fun,
add_regular_grid_of_size = grid_size_true,
sigma = sigma,
tau = tau,
L = L)
pfbm_curves <- lapply(pfbm$curves,
function(x) list(t = x$observed$t, x = x$observed$x,
grid_true = x$ideal$t,
x_true = x$ideal$x))
pfbm_mu <- lapply(pfbm_curves, function(curve) {
idx <- purrr::map_dbl(curve$t, ~which.min(abs(.x - mu_t$t)))
list(
t = curve$t,
x = curve$x + mu_t$mu[idx])
})
holder_estim <- estimate_holder_quantities(pfbm_mu, grid_param)
holder_Estim
holder_estim
holder_estim
rm(sigma)
devtools::load_all()
evalues_adaptive
estimate_bandwidth_evalues
evalues_pw <- evalues_adaptive(pfbm_mu, grid_bandwidth, grid_smooth,
k0, nvalues, holder_estim)
evalues_pw$eigenvalues
evalues_pw$bandwidth
holder_estim$sigma
sigma
efunctions_pw <- efunctions_adaptive(pfbm_mu, grid_bandwidth, grid_smooth,
k0, nfunctions, holder_estim)
efunctions_pw[. 1]
efunctions_pw$eigenfunctions
efunctions_pw$bandwidth
library(funeigen)
efunctions_adaptive
estimate_bandwidth_evalues
source("/Users/swang/Dropbox/FPCA/simuls/nice_dgp/dgp.R")
#source("/Users/swang/Dropbox/Mac/Downloads/juin15/codes_val/dgp_old.R")
# source("/Users/swang/Dropbox/funeigen/R/H_and_L_functions.R")
# source("/Users/swang/Dropbox/funeigen/R/mean_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/cov_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/utils.R")
# source("/Users/swang/Dropbox/funeigen/R/eigenvalues.R")
library(funeigen)
library(foreach)
library(fs)
library(doParallel)
library(functional)
library(purrr)
#parameters
N <- 200
M <- 200
#H <- c(0.5, 0.8)
sigma <- 0.5
L <- 1
mu0 <- 1
grid_size_true <- 101
grid_true <- seq(0, 1, length.out = grid_size_true)
grid_mu <- seq(0, 1, length.out = 1001)
grid_smooth <- seq(0, 1, length.out = 101)
grid_bandwidth <- lseq(0.001, 0.1, length.out = 51)
grid_param = seq(0.1, 0.9, length.out = 20)
k0 <- 1
n_simu <- 45
tau <- 2.5 #variance of random starting points
nvalues <- 10
nfunctions <- 10
points_dist <- Curry(runif, min = 0, max = 1) #distribution of Ti
#learn true quantities from dataset powerconsumption ===========================
library(simulater)
library(fda)
df <- powerconsumption
df_list <- list()
for (idx in 1:nrow(df)) {
df_list[[idx]] <- list(
't' = seq(0, 1, length.out = 1440),
'x' = unname(unlist(as.vector(df[idx,])))
)
}
n_basis <- 9  #other tested setups 7
t0_list <- seq(.1, .9, l = 40)
grid <- seq(.1, .9, l = 101)
#df_smooth <- presmoothing(df_list, t0_list = t0_list, estimate_sigma(df_list))
df_smooth <- funestim::presmoothing(df_list, t0_list)
H0 <- funestim::estimate_H0(df_smooth)
L0 <- funestim::estimate_L0(df_smooth, H0, M)
true_tibble = tibble::tibble(t = t0_list, H = H0, L = L0, sigma = sigma,
mu0 = mu0)
basis <- create.fourier.basis(rangeval = c(min(t0_list), max(t0_list)),
nbasis = n_basis)
H0_smooth <- smooth.basis(argvals = t0_list, y = H0, fdParobj = basis)
L0_smooth <- smooth.basis(argvals = t0_list, y = L0, fdParobj = basis)
H0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(H0_smooth))[, 1]
L0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(L0_smooth))[, 1]
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
constant_fun <- approxfun(
x = grid, y = L0_eval,
yleft = L0_eval[1], yright = L0_eval[length(L0_eval)]
)
grid_large <- seq(0, 1, l = 10001)
A_hat_prime <- constant_fun(grid_large)**(1 / hurst_fun(grid_large))
A_hat <- pracma::cumtrapz(x = grid_large, y = A_hat_prime)
A_fun <- approxfun(
x = grid_large, y = A_hat,
yleft = A_hat[1], yright = A_hat[length(A_hat)]
)
s <- exp(-3)  # Regularity for the estimation of the mean
##other tested setups 3
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
#true mean
mu_model <- learn_mean(df, k = 50)
mu <- predict_mean(grid_mu, mu_model, lambda = s, k = 50) - 240
mu_t <- tibble::tibble(t = grid_mu, mu)
#tested discretisation error on grid of 1001 points - very small
grid_cov <- seq(0, 1, length.out = 101)
pp_disto <- A_fun(grid_cov)
cov_true <- tau**2 + covariance_mfbm(grid_cov, hurst_fun, pp_disto)
#obtain the "numerically true" eigenvalues from the true covariance
evalues_true <- eigen(cov_true, symmetric = TRUE,
only.values = TRUE)$values[1:nvalues] / length(grid_cov)
efunctions_true <- eigen(cov_true, symmetric = TRUE)$vectors[, 1:nvalues] *
sqrt(length(grid_cov))
plot(bm_one$t, bm_proj_cum, type = "l")
bm_one <- list(t = seq(0, 1, l = 501),
x = c(somebm::bm(t0 = 0, t = 1, n = 500)))
nfun <- 5
plot(bm_one$t, bm_one$x, type = "l")
efun_bm <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
bm_proj <- sapply(seq_along(scores), function(k) {
scores[k] * efun_bm[, k]
})
bm_proj_cum <- apply(bm_proj, MARGIN = 1,
sum)
bm_proj_list <- lapply(seq(nfun), function(k) {
list(t = bm_one$t,
x = bm_proj[, k])
})
bm_df <- bm_proj_list |>
purrr::map(~tibble::as_tibble(.)) |>
dplyr::bind_rows(.id="eigenfunctions")
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
library(ggplot2)
bm_one <- list(t = seq(0, 1, l = 501),
x = c(somebm::bm(t0 = 0, t = 1, n = 500)))
nfun <- 5
plot(bm_one$t, bm_one$x, type = "l")
efun_bm <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
bm_proj <- sapply(seq_along(scores), function(k) {
scores[k] * efun_bm[, k]
})
bm_proj_cum <- apply(bm_proj, MARGIN = 1,
sum)
bm_proj_list <- lapply(seq(nfun), function(k) {
list(t = bm_one$t,
x = bm_proj[, k])
})
bm_df <- bm_proj_list |>
purrr::map(~tibble::as_tibble(.)) |>
dplyr::bind_rows(.id="eigenfunctions")
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
plot(bm_one$t, bm_proj_cum, type = "l")
plot(bm_one$t, bm_one$x, type = "l")
lines(bm_one$t, bm_proj_cum, col = "red")
nfun <- 10
bm_one <- list(t = seq(0, 1, l = 501),
x = c(somebm::bm(t0 = 0, t = 1, n = 500)))
nfun <- 10
efun_bm <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
bm_proj <- sapply(seq_along(scores), function(k) {
scores[k] * efun_bm[, k]
})
bm_proj_cum <- apply(bm_proj, MARGIN = 1,
sum)
bm_proj_list <- lapply(seq(nfun), function(k) {
list(t = bm_one$t,
x = bm_proj[, k])
})
bm_df <- bm_proj_list |>
purrr::map(~tibble::as_tibble(.)) |>
dplyr::bind_rows(.id="eigenfunctions")
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
plot(bm_one$t, bm_one$x, type = "l")
lines(bm_one$t, bm_proj_cum, col = "red")
bm_one <- list(t = seq(0, 1, l = 501),
x = c(somebm::bm(t0 = 0, t = 1, n = 500)))
nfun <- 5
efun_bm <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
bm_proj <- sapply(seq_along(scores), function(k) {
scores[k] * efun_bm[, k]
})
bm_proj_cum <- apply(bm_proj, MARGIN = 1,
sum)
bm_proj_list <- lapply(seq(nfun), function(k) {
list(t = bm_one$t,
x = bm_proj[, k])
})
bm_df <- bm_proj_list |>
purrr::map(~tibble::as_tibble(.)) |>
dplyr::bind_rows(.id="eigenfunctions")
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
plot(bm_one$t, bm_one$x, type = "l")
lines(bm_one$t, bm_proj_cum, col = "red")
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
plot(bm_one$t, bm_one$x, type = "l")
plot(bm_one$t, bm_one$x, type = "l", xlab = "t", ylab = "x")
bm_proj_cum
ggplot(bm_df, aes(x = t, y = x, group = eigenfunctions, col = eigenfunctions)) +
geom_line() +
theme_minimal()
plot(bm_one$t, bm_one$x, type = "l", xlab = "t", ylab = "x")
lines(bm_one$t, bm_proj_cum, col = "red")
efun_bm_big <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm_big <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores_big <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
bm_proj_big <- sapply(seq_along(scores), function(k) {
scores[k] * efun_bm[, k]
})
bm_proj_cum_big <- apply(bm_proj_big, MARGIN = 1,
sum)
plot(bm_one$t, bm_one$x, type = "l", xlab = "t", ylab = "x")
lines(bm_one$t, bm_proj_cum_big, col = "red")
nfun = 100
efun_bm_big <- sapply(seq(nfun), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm_big <- sapply(seq(nfun), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores_big <- sapply(seq(nfun), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm[, k])
})
nfun = 10
nfun_big = 100
efun_bm_big <- sapply(seq(nfun_big), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm_big <- sapply(seq(nfun_big), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores_big <- sapply(seq(nfun_big), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm_big[, k])
})
bm_proj_big <- sapply(seq_along(scores_big), function(k) {
scores_big[k] * eefun_bm_big[, k]
})
nfun_big = 100
efun_bm_big <- sapply(seq(nfun_big), function(k) {
sqrt(2) * sin((k - 0.5) * pi * bm_one$t)
})
eval_bm_big <- sapply(seq(nfun_big), function(k) {
1 / ((k - 0.5)**2 * pi**2)
})
scores_big <- sapply(seq(nfun_big), function(k) {
pracma::trapz(bm_one$t, bm_one$x * efun_bm_big[, k])
})
bm_proj_big <- sapply(seq_along(scores_big), function(k) {
scores_big[k] * efun_bm_big[, k]
})
bm_proj_cum_big <- apply(bm_proj_big, MARGIN = 1,
sum)
plot(bm_one$t, bm_one$x, type = "l", xlab = "t", ylab = "x")
lines(bm_one$t, bm_proj_cum_big, col = "red")
plot(bm_one$t, bm_one$x, type = "l", xlab = "t", ylab = "x")
lines(bm_one$t, bm_proj_cum, col = "red")
lines(bm_one$t, bm_proj_cum_big, col = "green")
# set the seed for reproducibility
set.seed(123)
# specify the number of time steps
n_steps <- 1000
# specify the time step size
dt <- 0.01
# generate white noise with a standard deviation of 1 and mean of 0
wn <- rnorm(n_steps, mean = 0, sd = 1)
# calculate the VAR(1) process for different values of A(1)
A1 <- c(0.9, 0.99, 1.1, 1.5)
var1 <- list()
for (a in A1) {
var1[[a]] <- cumsum(a * wn[-1] + wn) * sqrt(dt)
}
# plot the VAR(1) processes
par(mfrow = c(2, 2))
for (a in A1) {
plot(var1[[a]], type = "l", main = paste("A(1) =", a))
}
A = cbind(c(1, -0.4, 0.2, 0), c(-0.4, 1.2, 0, 0), c(0.2, -0.4, 1, 0),
c(0, 0.2, -0.4, 1))
A
solve(A)
solve(A)%*%c(12.8, 0, 0, 0)
dim(solve(A))
B = c(12.8, 0, 0, 0)
solve(A) %*% B
A = rbind(c(1, -0.4, 0.2, 0), c(-0.4, 1.2, 0, 0), c(0.2, -0.4, 1, 0),
c(0, 0.2, -0.4, 1))
A
solve(A) %*% B
A = rbind(c(1, 1, 1/3, 1/27), c(1, 4/3, 1/27, 0), c(1/3, 28/27, 1, 0),
c(1/27, 1/3, 1, 1))
A
solve(A) %*% c(1, 0, 0, 0)
?kronecker
matrix(c(0.5, 0.4, 0.1, 0.8))
matrix(0.5, 0.4, 0.1, 0.8)
matrix(rbind(c(0.5, 0.4), c(0.1, 0.8)))
rbind(c(0.5, 0.4), c(0.1, 0.8))
B = rbind(c(0.5, 0.4), c(0.1, 0.8))
B
B %x% B
diag(nrow = 4, ncol = 4)
diag(nrow = 4, ncol = 4) - B %x% B
solve(diag(nrow = 4, ncol = 4) - B %x% B)
solve(diag(nrow = 4, ncol = 4) - B %x% B) %*% c(1, 0.6, 0.6, 1)
C = matrix(c(0.5, 0.1, 0, 0.4), nrow = 2, ncol = 2)
C
C = matrix(c(0.5, 0, 0.1, 0.4), nrow = 2, ncol = 2)
C
diag(nrow = 4, ncol = 4)
C %x% C
solve(diag(nrow = 4, ncol = 4) -  C%x%C)
solve(diag(nrow = 4, ncol = 4) -  C%x%C) %*% c(3, 0.7, 0.7, 1)
