grid_true = x$ideal$t,
x_true = x$ideal$x))
pfbm_mu <- lapply(pfbm_curves, function(curve) {
idx <- purrr::map_dbl(curve$t, ~which.min(abs(.x - mu_t$t)))
list(
t = curve$t,
x = curve$x + mu_t$mu[idx]
)
})
holder <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = FALSE)
holder_weighted <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = FALSE)
holder_cv <-  estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = TRUE,
n_sample = 20)
holder_cv_weights <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = TRUE,
n_sample = 20)
holder_cv_weights
holder_cv_weights$H
gc(\)
gc()
source("/Users/swang/Dropbox/Mac/Downloads/codes_alternative_power/dgp_old.R")
library(tibble)
library(purrr)
devtools::load_all()
#parameters
N <- 200
M <- 25
#H <- c(0.5, 0.8)
sigma <- 0.3
L <- 1
mu0 <- 1
grid_size_true <- 101
grid_true <- seq(0, 1, length.out = grid_size_true)
grid_mu <- seq(0, 1, length.out = 1001)
grid_smooth <- seq(0, 1, length.out = 101)
grid_param = seq(0.2, 0.8, length.out = 21)
k0 <- 1
n_simu <- 450
k_length <- 100
alpha <- 4
#change_point <- 0.5
#slope <- 50
tau <- 2.5 #variance of random starting points
# scale <- 1
# shift <- 0
nvalues <- 10
points_dist <- functional::Curry(runif, min = 0, max = 1) #distribution of Ti
h_first = 0.4
h_second = 0.8
cov_true = tau**2 + covariance_mfbm(grid_smooth, hurst_logistic)
hurst_logistic <- function(
t_vec,
h_left = h_first,
h_right = h_second,
slope = 20,
change_point_position = 0.5
) {
change_point <- change_point_position * (max(t_vec) + min(t_vec))
u <- (t_vec - change_point) / (max(t_vec) - min(t_vec))
(h_right - h_left) / (1 + exp(-slope * u)) + h_left
}
#generate mean curve
generate_mean_curve <- function(k_length, grid_t = seq(0, 1, length.out = 101),
alpha, shift = 0, scale_mu = 1) {
Z <- runif(k_length, -sqrt(3), sqrt(3))
#Z <- rnorm(k_length)
xi <- c()
# for(i in 1:k_length) {
#   xi_k <- (-1)^(i+1)*i^(-alpha)
#   xi <- c(xi, xi_k)
# }
for(i in 1:k_length) {
xi_k <- 1/((i - 1/2)^alpha*pi^2)
xi <- c(xi, xi_k)
}
k <- seq(1, k_length, by = 1)
# mu_kt <- sapply(grid_t, function(t) {
#   Z * sqrt(xi) * cos(k * pi * t)
# })
mu_kt <- sapply(grid_t, function(t) {
sqrt(2) * Z * sqrt(xi) * sin((k - 0.5) * pi * t)
})
mu_t <- scale_mu * colSums(mu_kt) + rep(shift, length(grid))
tibble(t = grid_t, mu = mu_t)
}
mu_t <- generate_mean_curve(k_length, grid_smooth, alpha)
H_vec <- c(rep(h_first, round(length(grid_smooth) / 2)),
rep(h_second, length(grid_smooth) - round(length(grid_smooth) / 2)))
L_vec <- rep(L, length(grid_smooth))
sigma_vec <- rep(sigma, length(grid_smooth))
mu0_vec <- rep(mu0, length(grid_smooth))
true_tibble <- tibble::tibble(t = grid_smooth,
H = H_vec,
L = L_vec,
sigma = sigma_vec,
mu0 = mu0_vec)
n_simu
n_simu = 180
n_simu = 90
library(foreach)
library(fs)
library(doParallel)
intermediate_directory <- './intermediate'
if (!dir.exists(intermediate_directory)){
dir.create(intermediate_directory)
}
cl <- parallel::makeCluster(9)
doParallel::registerDoParallel(cl)
tictoc::tic()
foreach::foreach(i = 1:n_simu,
.packages = c("dplyr", "MASS", "rpart", "matrixStats",
"purrr", "functional")) %dopar%
{
each_filename <- paste0('RESULT_N', N, '_M', M, '_', as.character(i),
'.rda')
each_filepath <- file.path(intermediate_directory, each_filename)
if (file.exists(each_filepath)) {
next
}
devtools::load_all()
points_list <- generates_points(N = N, m = M)
pfbm <- generate_curves(points_list,
hurst = hurst_logistic,
add_regular_grid_of_size = grid_size_true,
sigma = sigma,
tau = tau,
L = L)
pfbm_curves <- lapply(pfbm$curves,
function(x) list(t = x$observed$t, x = x$observed$x,
grid_true = x$ideal$t,
x_true = x$ideal$x))
pfbm_mu <- lapply(pfbm_curves, function(curve) {
idx <- purrr::map_dbl(curve$t, ~which.min(abs(.x - mu_t$t)))
list(
t = curve$t,
x = curve$x + mu_t$mu[idx]
)
})
holder <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = FALSE)
holder_weighted <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = FALSE)
holder_cv <-  estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = TRUE,
n_sample = 20)
holder_cv_weights <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = TRUE,
n_sample = 20)
result <- list(
'holder' = holder,
'holder_weighted' = holder_weighted,
'holder_cv' = holder_cv,
'holder_cv_weights' = holder_cv_weights
)
save(result, file = each_filepath)
}
?npregbw
stopCluster(cl)
gc()
source("/Users/swang/Dropbox/Mac/Downloads/codes_alternative_power/dgp_old.R")
library(tibble)
library(purrr)
devtools::load_all()
#parameters
N <- 200
M <- 25
#H <- c(0.5, 0.8)
sigma <- 0.3
L <- 1
mu0 <- 1
grid_size_true <- 101
grid_true <- seq(0, 1, length.out = grid_size_true)
grid_mu <- seq(0, 1, length.out = 1001)
grid_smooth <- seq(0, 1, length.out = 101)
grid_param = seq(0.2, 0.8, length.out = 21)
k0 <- 1
n_simu <- 450
k_length <- 100
alpha <- 4
#change_point <- 0.5
#slope <- 50
tau <- 2.5 #variance of random starting points
# scale <- 1
# shift <- 0
nvalues <- 10
points_dist <- functional::Curry(runif, min = 0, max = 1) #distribution of Ti
h_first = 0.4
h_second = 0.8
cov_true = tau**2 + covariance_mfbm(grid_smooth, hurst_logistic)
hurst_logistic <- function(
t_vec,
h_left = h_first,
h_right = h_second,
slope = 20,
change_point_position = 0.5
) {
change_point <- change_point_position * (max(t_vec) + min(t_vec))
u <- (t_vec - change_point) / (max(t_vec) - min(t_vec))
(h_right - h_left) / (1 + exp(-slope * u)) + h_left
}
#generate mean curve
generate_mean_curve <- function(k_length, grid_t = seq(0, 1, length.out = 101),
alpha, shift = 0, scale_mu = 1) {
Z <- runif(k_length, -sqrt(3), sqrt(3))
#Z <- rnorm(k_length)
xi <- c()
# for(i in 1:k_length) {
#   xi_k <- (-1)^(i+1)*i^(-alpha)
#   xi <- c(xi, xi_k)
# }
for(i in 1:k_length) {
xi_k <- 1/((i - 1/2)^alpha*pi^2)
xi <- c(xi, xi_k)
}
k <- seq(1, k_length, by = 1)
# mu_kt <- sapply(grid_t, function(t) {
#   Z * sqrt(xi) * cos(k * pi * t)
# })
mu_kt <- sapply(grid_t, function(t) {
sqrt(2) * Z * sqrt(xi) * sin((k - 0.5) * pi * t)
})
mu_t <- scale_mu * colSums(mu_kt) + rep(shift, length(grid))
tibble(t = grid_t, mu = mu_t)
}
mu_t <- generate_mean_curve(k_length, grid_smooth, alpha)
H_vec <- c(rep(h_first, round(length(grid_smooth) / 2)),
rep(h_second, length(grid_smooth) - round(length(grid_smooth) / 2)))
L_vec <- rep(L, length(grid_smooth))
sigma_vec <- rep(sigma, length(grid_smooth))
mu0_vec <- rep(mu0, length(grid_smooth))
true_tibble <- tibble::tibble(t = grid_smooth,
H = H_vec,
L = L_vec,
sigma = sigma_vec,
mu0 = mu0_vec)
library(foreach)
library(fs)
library(doParallel)
intermediate_directory <- './intermediate'
if (!dir.exists(intermediate_directory)){
dir.create(intermediate_directory)
}
cl <- parallel::makeCluster(9)
doParallel::registerDoParallel(cl)
tictoc::tic()
foreach::foreach(i = 1:n_simu,
.packages = c("dplyr", "MASS", "rpart", "matrixStats",
"purrr", "functional", "np")) %dopar%
{
each_filename <- paste0('RESULT_N', N, '_M', M, '_', as.character(i),
'.rda')
each_filepath <- file.path(intermediate_directory, each_filename)
if (file.exists(each_filepath)) {
next
}
devtools::load_all()
points_list <- generates_points(N = N, m = M)
pfbm <- generate_curves(points_list,
hurst = hurst_logistic,
add_regular_grid_of_size = grid_size_true,
sigma = sigma,
tau = tau,
L = L)
pfbm_curves <- lapply(pfbm$curves,
function(x) list(t = x$observed$t, x = x$observed$x,
grid_true = x$ideal$t,
x_true = x$ideal$x))
pfbm_mu <- lapply(pfbm_curves, function(curve) {
idx <- purrr::map_dbl(curve$t, ~which.min(abs(.x - mu_t$t)))
list(
t = curve$t,
x = curve$x + mu_t$mu[idx]
)
})
holder <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = FALSE)
holder_weighted <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = FALSE)
holder_cv <-  estimate_holder_quantities(pfbm_mu, grid_param,
weighted = FALSE, cv = TRUE,
n_sample = 20)
holder_cv_weights <- estimate_holder_quantities(pfbm_mu, grid_param,
weighted = TRUE, cv = TRUE,
n_sample = 20)
result <- list(
'holder' = holder,
'holder_weighted' = holder_weighted,
'holder_cv' = holder_cv,
'holder_cv_weights' = holder_cv_weights
)
save(result, file = each_filepath)
}
tictoc::toc()
stopCluster(cl)
fls <- list.files(intermediate_directory, pattern = 'rda')
result_list <- lapply(fls,
function(x) get(eval(load(paste0(intermediate_directory, '/', x
)))))
save(result_list, file = paste0('holder', 'N = ', N, 'M = ', M, '.rda'))
path <- paste0(getwd(), '/intermediate')
file_delete(path)
result_list[[1]]$holder_cv
#==============with cross-validation
H_cv <- sapply(result_list, function(x) x$holder_cv$H)
result_list[[1]]$holder_cv_weights
H_cv_weighted <- sapply(result_list, function(x) x$holder_cv_weights$H)
H_cv <- sapply(result_list, function(x) x$holder_cv$H)
H_cv_weighted <- sapply(result_list, function(x) x$holder_cv_weights$H)
H_cv_err_1st <- t(abs(H_cv[1:idx_0.5,] - h_first))
idx_0.5 <- which.min(abs(grid_param - 0.5))
H_cv_err_1st <- t(abs(H_cv[1:idx_0.5,] - h_first))
H_cv_err_2nd <- t(abs(H_cv[(idx_0.5 + 1):length(grid_param), ] - h_second))
H_cv_tibble <- stack(as.data.frame(cbind(H_cv_err_1st,
H_cv_err_2nd)))
H_cv_tibble
H_cv_weighted_err_1st <- t(abs(H_cv_weighted[1:idx_0.5,] - h_first))
H_cv_weighted_err_2nd <- t(abs(H_cv_weighted[(idx_0.5 + 1):length(grid_param), ] - h_second))
H_cv_weighted_tibble <- stack(as.data.frame(cbind(H_cv_weighted_err_1st,
H_cv_weighted_err_2nd)))
H_cv_weighted_tibble
H_cv_tibble
head(H_cv_tibble)
boxplot_H_cv <- ggplot(H_cv_tibble, aes(x = ind, y = values, fill = ind)) +
geom_boxplot() +
ggtitle("Estimated H (CV without weighting scheme)") +
xlab("Grid Points") +
ylab("Absolute Errors")
boxplot_H_cv_weighted <- ggplot(H_cv_weighted_tibble, aes(x = ind, y = values, fill = ind)) +
geom_boxplot() +
ggtitle("Estimated H (CV with weighting scheme)") +
xlab("Grid Points") +
ylab("Absolute Errors")
plot_layout(guides = "collect") &
theme(legend.position = "bottom")
boxplot_H_germans + boxplot_H_germans_weighted + boxplot_H_cv + boxplot_H_cv_weighted +
plot_layout(guides = "collect") &
theme(legend.position = "bottom")
idx_0.5 <- which.min(abs(grid_param - 0.5))
H_germans <- sapply(result_list, function(x) x$holder$H)
H_germans_weighted <- sapply(result_list, function(x) x$holder_weighted$H)
H_germans_err_1st <- t(abs(H_germans[1:idx_0.5,] - h_first))
H_germans_err_2nd <- t(abs(H_germans[(idx_0.5 + 1):length(grid_param), ] - h_second))
H_germans_tibble <- stack(as.data.frame(cbind(H_germans_err_1st,
H_germans_err_2nd)))
H_germans_weighted_err_1st <- t(abs(H_germans_weighted[1:idx_0.5,] - h_first))
H_germans_weighted_err_2nd <- t(abs(H_germans_weighted[(idx_0.5 + 1):length(grid_param), ] - h_second))
H_germans_weighted_tibble <- stack(as.data.frame(cbind(H_germans_weighted_err_1st,
H_germans_weighted_err_2nd)))
boxplot_H_germans <- ggplot(H_germans_tibble, aes(x = ind, y = values, fill = ind)) +
geom_boxplot() +
ggtitle("Estimated H (Germans without weighting scheme)") +
xlab("Grid Points") +
ylab("Absolute Errors")
boxplot_H_germans_weighted <- ggplot(H_germans_weighted_tibble, aes(x = ind,
y = values, fill = ind)) +
geom_boxplot() +
ggtitle("Estimated H (Germans with weighting scheme)") +
xlab("Grid Points") +
ylab("Absolute Errors")
boxplot_H_germans + boxplot_H_germans_weighted + boxplot_H_cv + boxplot_H_cv_weighted +
plot_layout(guides = "collect") &
theme(legend.position = "bottom")
H_cv_weighted
H_cv_weighted[21, ]
apply(H_cv_weighted, 1, mean)
apply(L_cv_weighted, 1, mean)
L_cv_weighted <- sapply(result_list, function(x) x$holder_cv$L)
apply(L_cv_weighted, 1, mean)
L_cv <- sapply(result_list, function(x) x$holder_cv$L)
apply(L_cv, 1, mean)
L_cv_weighted <-  sapply(result_list, function(x) x$holder_cv_weighted$L)
apply(L_cv_weighted, 1, mean)
L_cv_weighted <-  sapply(result_list, function(x) x$holder_cv_weights$L)
apply(L_cv_weighted, 1, mean)
M
N
estimate_holder_quantities
source("/Users/swang/Dropbox/FPCA/simuls/nice_dgp/dgp.R")
#source("/Users/swang/Dropbox/Mac/Downloads/juin15/codes_val/dgp_old.R")
# source("/Users/swang/Dropbox/funeigen/R/H_and_L_functions.R")
# source("/Users/swang/Dropbox/funeigen/R/mean_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/cov_optimised.R")
# source("/Users/swang/Dropbox/funeigen/R/utils.R")
# source("/Users/swang/Dropbox/funeigen/R/eigenvalues.R")
library(funeigen)
library(foreach)
library(fs)
library(doParallel)
library(functional)
library(purrr)
#parameters
N <- 200
M <- 25
#H <- c(0.5, 0.8)
sigma <- 0.5
L <- 1
mu0 <- 1
grid_size_true <- 101
grid_true <- seq(0, 1, length.out = grid_size_true)
grid_mu <- seq(0, 1, length.out = 1001)
grid_smooth <- seq(0, 1, length.out = 101)
grid_bandwidth <- lseq(0.001, 0.1, length.out = 51)
grid_param = seq(0.1, 0.9, length.out = 20)
k0 <- 1
n_simu <- 45
tau <- 2.5 #variance of random starting points
nvalues <- 10
nfunctions <- 10
points_dist <- Curry(runif, min = 0, max = 1) #distribution of Ti
#learn true quantities from dataset powerconsumption ===========================
library(simulater)
library(fda)
df <- powerconsumption
df_list <- list()
for (idx in 1:nrow(df)) {
df_list[[idx]] <- list(
't' = seq(0, 1, length.out = 1440),
'x' = unname(unlist(as.vector(df[idx,])))
)
}
n_basis <- 9  #other tested setups 7
t0_list <- seq(.1, .9, l = 40)
grid <- seq(.1, .9, l = 101)
#df_smooth <- presmoothing(df_list, t0_list = t0_list, estimate_sigma(df_list))
df_smooth <- funestim::presmoothing(df_list, t0_list)
H0 <- funestim::estimate_H0(df_smooth)
L0 <- funestim::estimate_L0(df_smooth, H0, M)
true_tibble = tibble::tibble(t = t0_list, H = H0, L = L0, sigma = sigma,
mu0 = mu0)
basis <- create.fourier.basis(rangeval = c(min(t0_list), max(t0_list)),
nbasis = n_basis)
H0_smooth <- smooth.basis(argvals = t0_list, y = H0, fdParobj = basis)
L0_smooth <- smooth.basis(argvals = t0_list, y = L0, fdParobj = basis)
H0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(H0_smooth))[, 1]
L0_eval <- eval.fd(evalarg = grid, fdobj = as.fd(L0_smooth))[, 1]
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
constant_fun <- approxfun(
x = grid, y = L0_eval,
yleft = L0_eval[1], yright = L0_eval[length(L0_eval)]
)
grid_large <- seq(0, 1, l = 10001)
A_hat_prime <- constant_fun(grid_large)**(1 / hurst_fun(grid_large))
A_hat <- pracma::cumtrapz(x = grid_large, y = A_hat_prime)
A_fun <- approxfun(
x = grid_large, y = A_hat,
yleft = A_hat[1], yright = A_hat[length(A_hat)]
)
s <- exp(-3)  # Regularity for the estimation of the mean
##other tested setups 3
hurst_fun <- approxfun(
x = grid, y = H0_eval,
yleft = H0_eval[1], yright = H0_eval[length(H0_eval)]
)
#true mean
mu_model <- learn_mean(df, k = 50)
mu <- predict_mean(grid_mu, mu_model, lambda = s, k = 50) - 240
mu_t <- tibble::tibble(t = grid_mu, mu)
#tested discretisation error on grid of 1001 points - very small
grid_cov <- seq(0, 1, length.out = 101)
pp_disto <- A_fun(grid_cov)
cov_true <- tau**2 + covariance_mfbm(grid_cov, hurst_fun, pp_disto)
#obtain the "numerically true" eigenvalues from the true covariance
evalues_true <- eigen(cov_true, symmetric = TRUE,
only.values = TRUE)$values[1:nvalues] / length(grid_cov)
efunctions_true <- eigen(cov_true, symmetric = TRUE)$vectors[, 1:nvalues] *
sqrt(length(grid_cov))
points_list <- generates_points(N = N, m = M)
pfbm <- generate_curves(points_list, hurst_fun,
distortion_model = A_fun,
add_regular_grid_of_size = grid_size_true,
sigma = sigma,
tau = tau,
L = L)
pfbm_curves <- lapply(pfbm$curves,
function(x) list(t = x$observed$t, x = x$observed$x,
grid_true = x$ideal$t,
x_true = x$ideal$x))
pfbm_mu <- lapply(pfbm_curves, function(curve) {
idx <- purrr::map_dbl(curve$t, ~which.min(abs(.x - mu_t$t)))
list(
t = curve$t,
x = curve$x + mu_t$mu[idx])
})
H0_smooth
test = estimate_holder_quantities(pfbm_mu, grid_param, weighted = TRUE, cv = TRUE)
test
test = estimate_holder_quantities(pfbm_mu, grid_param, weighted = TRUE, cv = FALSE)
test
test$H
H0_smooth$y
estimate_density(pfbm)
estimate_density(pfbm_mu)
?npuniden.boundary
T_all <- purrr::map(data, ~.x$t) |> unlist() |> sort()
T_all <- purrr::map(pfbm_mu, ~.x$t) |> unlist() |> sort()
T_all
npuniden.boundary(T_all)
test = npuniden.boundary(T_all)
test$f
test$f |> min()
test$f |> max()
test$F
document()
hurst_fun
funeigen::estimate_bandwidth_evalues
log(10000)
